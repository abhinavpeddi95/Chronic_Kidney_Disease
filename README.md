# Chronic_Kidney_Disease classification

The project uses patient health attribute data to train and evaluate classification models for chronic kidney disease (CKD). The task is to classify instances of CKD using the dataset and multiple classification models. The dataset undergoes data cleaning, exploratory data analysis (EDA), and missing value treatment. Various classification models, including Random Forest, Ada Boost, CatBoost, Decision Tree, and Extra Tree Classifiers, are employed for CKD classification. Model performance is evaluated using accuracy score, confusion matrix, and classification report. The project successfully applies machine learning techniques to classify instances of CKD using patient health attribute data. The dataset is preprocessed through data cleaning, EDA, and missing value treatment. Various classification models, such as Random Forest, Ada Boost, CatBoost, Decision Tree, and Extra Tree Classifiers, are utilized. Model performance is assessed using accuracy score, confusion matrix, and classification report.

# Dataset
The dataset used in this project is sourced from the UCI Machine Learning Repository and consists of instances representing patient records with 24 attributes. These attributes include patient demographic information, symptoms, and laboratory test results. The target variable indicates the presence or absence of Chronic Kidney Disease.

# Project Structure
<b>kidney_disease.csv</b>: This file contains the dataset used for training and testing the models. 

<b>Chronic_kidney_disease.ipynb</b>: This file contains Jupyter notebooks used for data exploration, preprocessing, model training, and evaluation.

# Requirements
To run the code in this repository, you need the following dependencies:

Python 3.7 or above
Required Python libraries listed in the requirements.txt file. Install them using pip install -r requirements.txt.

# Usage
1. Clone or download this repository to your local machine.
2. Install the required dependencies as mentioned in the Requirements section.
3. Place the dataset file(s) in the data/ directory.
4. Explore the Jupyter notebooks in the notebooks/ directory to understand the project flow and execute code cells.
5. Train and evaluate classification models using the provided notebooks.

# Contributing
Contributions to this project are welcome. If you have any suggestions, bug reports, or improvements, feel free to open an issue or submit a pull request.

# License
The dataset is obtained as per MIT License. Feel free to use the code, modify it, or distribute the dataset as per the terms of the MIT license.
